"""removed data source id from data models

Revision ID: 450bd09cd019
Revises: db8068acf2bd
Create Date: 2025-10-03 04:58:50.033658

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# Import the custom ArrayType
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
from cortex.core.types.databases import ArrayType

# revision identifiers, used by Alembic.
revision: str = '450bd09cd019'
down_revision: Union[str, None] = 'db8068acf2bd'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Check if we're on SQLite or PostgreSQL
    bind = op.get_bind()
    dialect_name = bind.dialect.name
    
    if dialect_name == 'sqlite':
        # For SQLite, use direct SQL commands since batch operations can be problematic
        # Drop the column by recreating the table
        op.execute("""
            CREATE TABLE data_models_new (
                id UUID PRIMARY KEY NOT NULL,
                name VARCHAR NOT NULL,
                alias VARCHAR,
                description TEXT,
                version INTEGER NOT NULL,
                is_active BOOLEAN NOT NULL,
                parent_version_id UUID,
                config JSON NOT NULL,
                is_valid BOOLEAN NOT NULL,
                validation_errors JSON,
                created_at DATETIME,
                updated_at DATETIME
            )
        """)
        
        op.execute("""
            INSERT INTO data_models_new (id, name, alias, description, version, is_active, parent_version_id, config, is_valid, validation_errors, created_at, updated_at)
            SELECT id, name, alias, description, version, is_active, parent_version_id, config, is_valid, validation_errors, created_at, updated_at
            FROM data_models
        """)
        
        op.execute("DROP TABLE data_models")
        op.execute("ALTER TABLE data_models_new RENAME TO data_models")
        
    else:
        # For PostgreSQL, use standard operations
        op.drop_constraint('data_models_data_source_id_fkey', 'data_models', type_='foreignkey')
        op.drop_index('ix_data_models_data_source_id', 'data_models')
        op.drop_column('data_models', 'data_source_id')
        
        # Update array types
        op.alter_column('data_models', 'validation_errors',
                   existing_type=postgresql.ARRAY(sa.VARCHAR()),
                   type_=ArrayType(),
                   existing_nullable=True)
        op.alter_column('metric_versions', 'tags',
                   existing_type=postgresql.ARRAY(sa.VARCHAR()),
                   type_=ArrayType(),
                   existing_nullable=True)
        op.alter_column('metrics', 'validation_errors',
                   existing_type=postgresql.ARRAY(sa.VARCHAR()),
                   type_=ArrayType(),
                   existing_nullable=True)
        op.alter_column('model_versions', 'validation_errors',
                   existing_type=postgresql.ARRAY(sa.VARCHAR()),
                   type_=ArrayType(),
                   existing_nullable=True)
        op.alter_column('model_versions', 'tags',
                   existing_type=postgresql.ARRAY(sa.VARCHAR()),
                   type_=ArrayType(),
                   existing_nullable=True)
    # ### end Alembic commands ###



def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Check if we're on SQLite or PostgreSQL
    bind = op.get_bind()
    dialect_name = bind.dialect.name
    
    if dialect_name == 'sqlite':
        # For SQLite, recreate table with data_source_id column
        op.execute("""
            CREATE TABLE data_models_new (
                id UUID PRIMARY KEY NOT NULL,
                data_source_id UUID,
                name VARCHAR NOT NULL,
                alias VARCHAR,
                description TEXT,
                version INTEGER NOT NULL,
                is_active BOOLEAN NOT NULL,
                parent_version_id UUID,
                config JSON NOT NULL,
                is_valid BOOLEAN NOT NULL,
                validation_errors JSON,
                created_at DATETIME,
                updated_at DATETIME
            )
        """)
        
        op.execute("""
            INSERT INTO data_models_new (id, name, alias, description, version, is_active, parent_version_id, config, is_valid, validation_errors, created_at, updated_at)
            SELECT id, name, alias, description, version, is_active, parent_version_id, config, is_valid, validation_errors, created_at, updated_at
            FROM data_models
        """)
        
        op.execute("DROP TABLE data_models")
        op.execute("ALTER TABLE data_models_new RENAME TO data_models")
        
    else:
        # For PostgreSQL, use standard operations
        op.alter_column('model_versions', 'tags',
                   existing_type=ArrayType(),
                   type_=postgresql.ARRAY(sa.VARCHAR()),
                   existing_nullable=True)
        op.alter_column('model_versions', 'validation_errors',
                   existing_type=ArrayType(),
                   type_=postgresql.ARRAY(sa.VARCHAR()),
                   existing_nullable=True)
        op.alter_column('metrics', 'validation_errors',
                   existing_type=ArrayType(),
                   type_=postgresql.ARRAY(sa.VARCHAR()),
                   existing_nullable=True)
        op.alter_column('metric_versions', 'tags',
                   existing_type=ArrayType(),
                   type_=postgresql.ARRAY(sa.VARCHAR()),
                   existing_nullable=True)
        op.alter_column('data_models', 'validation_errors',
                   existing_type=ArrayType(),
                   type_=postgresql.ARRAY(sa.VARCHAR()),
                   existing_nullable=True)
        
        # Add back data_source_id column
        op.add_column('data_models', sa.Column('data_source_id', sa.UUID(), nullable=True))
        op.create_index('ix_data_models_data_source_id', 'data_models', ['data_source_id'])
        op.create_foreign_key('data_models_data_source_id_fkey', 'data_models', 'data_sources', ['data_source_id'], ['id'])
    # ### end Alembic commands ###
